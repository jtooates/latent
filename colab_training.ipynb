{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jtooates/latent/blob/main/colab_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Latent Canvas Painter - GPU Training on Colab\n",
    "\n",
    "This notebook sets up and trains the DRAW-style canvas painter model on Google Colab with GPU acceleration.\n",
    "\n",
    "## Features:\n",
    "- Automatic GPU detection and usage\n",
    "- Google Drive integration for checkpoint persistence\n",
    "- Optimized batch size for GPU training\n",
    "- Resume training from saved checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected. Training will be slow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive for checkpoint persistence\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directory for this project\n",
    "import os\n",
    "project_dir = '/content/drive/MyDrive/latent_training'\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "print(f\"Project directory: {project_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/jtooates/latent.git\n",
    "%cd latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Install dependencies (Pillow for image visualization)\n",
    "!pip install -q Pillow\n",
    "print(\"Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config-header"
   },
   "source": [
    "## 2. Configure Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config-params"
   },
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128  # Larger batch size for GPU\n",
    "LEARNING_RATE = 0.001\n",
    "LATENT_SIZE = 48  # Larger canvas\n",
    "PATCH_SIZE = 7  # Larger patches\n",
    "NUM_STEPS = 0  # Adaptive (use num tokens)\n",
    "\n",
    "# Checkpoint settings\n",
    "CHECKPOINT_DIR = f\"{project_dir}/checkpoints\"\n",
    "RESUME_CHECKPOINT = None  # Set to checkpoint path to resume\n",
    "\n",
    "# Display settings\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  Canvas Size: {LATENT_SIZE}x{LATENT_SIZE}\")\n",
    "print(f\"  Patch Size: {PATCH_SIZE}x{PATCH_SIZE}\")\n",
    "print(f\"  Painting Steps: {'adaptive' if NUM_STEPS == 0 else NUM_STEPS}\")\n",
    "print(f\"  Checkpoint Dir: {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train-header"
   },
   "source": [
    "## 3. Train Model\n",
    "\n",
    "This cell will start training. On a GPU, training should be significantly faster than CPU.\n",
    "\n",
    "**Expected speeds:**\n",
    "- CPU: ~2-5 minutes per epoch\n",
    "- GPU (T4): ~10-30 seconds per epoch\n",
    "- GPU (V100/A100): ~5-15 seconds per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-model"
   },
   "outputs": [],
   "source": [
    "# Build training command\n",
    "cmd = f\"\"\"python train.py \\\n",
    "    --data training_data.json \\\n",
    "    --config training_config.json \\\n",
    "    --use-canvas-painter \\\n",
    "    --epochs {EPOCHS} \\\n",
    "    --batch-size {BATCH_SIZE} \\\n",
    "    --lr {LEARNING_RATE} \\\n",
    "    --latent-size {LATENT_SIZE} \\\n",
    "    --painter-patch-size {PATCH_SIZE} \\\n",
    "    --painter-num-steps {NUM_STEPS} \\\n",
    "    --output-dir {CHECKPOINT_DIR}\"\"\"\n",
    "\n",
    "# Add resume flag if checkpoint specified\n",
    "if RESUME_CHECKPOINT:\n",
    "    cmd += f\" --resume {RESUME_CHECKPOINT}\"\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "resume-header"
   },
   "source": [
    "## 4. Resume Training (Optional)\n",
    "\n",
    "If training was interrupted, you can resume from the last checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "resume-training"
   },
   "outputs": [],
   "source": [
    "# List available checkpoints\n",
    "import os\n",
    "checkpoint_path = f\"{CHECKPOINT_DIR}/best_model.pt\"\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Found checkpoint: {checkpoint_path}\")\n",
    "    print(\"\\nTo resume training, run the cell below or update RESUME_CHECKPOINT above and rerun training cell.\")\n",
    "else:\n",
    "    print(\"No checkpoint found yet. Train first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "resume-cmd"
   },
   "outputs": [],
   "source": [
    "# Quick resume command (runs 50 more epochs)\n",
    "!python train.py \\\n",
    "    --data training_data.json \\\n",
    "    --config training_config.json \\\n",
    "    --resume {CHECKPOINT_DIR}/best_model.pt \\\n",
    "    --epochs 150 \\\n",
    "    --batch-size {BATCH_SIZE} \\\n",
    "    --output-dir {CHECKPOINT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viz-header"
   },
   "source": [
    "## 5. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz-latents"
   },
   "outputs": [],
   "source": [
    "# Display some latent images\n",
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "# Get latest epoch images\n",
    "image_dir = f\"{CHECKPOINT_DIR}/latent_images\"\n",
    "if os.path.exists(image_dir):\n",
    "    images = sorted(glob.glob(f\"{image_dir}/*.png\"))[-8:]  # Last 8 images\n",
    "    print(f\"Displaying {len(images)} latent images:\\n\")\n",
    "    for img_path in images:\n",
    "        print(os.path.basename(img_path))\n",
    "        display(Image(img_path, width=256))\n",
    "else:\n",
    "    print(\"No images generated yet. Set --save-images-every in training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz-saliency"
   },
   "outputs": [],
   "source": [
    "# Generate saliency visualization for a test sentence\n",
    "test_sentence = \"red circle on blue square\"\n",
    "output_path = f\"{project_dir}/saliency_test.png\"\n",
    "\n",
    "!python visualize_saliency.py \\\n",
    "    --checkpoint {CHECKPOINT_DIR}/best_model.pt \\\n",
    "    --data training_data.json \\\n",
    "    --sentence \"{test_sentence}\" \\\n",
    "    --output {output_path}\n",
    "\n",
    "# Display result\n",
    "if os.path.exists(output_path):\n",
    "    print(f\"\\nSaliency map for: '{test_sentence}'\")\n",
    "    display(Image(output_path, width=512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-header"
   },
   "source": [
    "## 6. Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-model"
   },
   "outputs": [],
   "source": [
    "# Download the best model to your local machine\n",
    "from google.colab import files\n",
    "\n",
    "checkpoint_file = f\"{CHECKPOINT_DIR}/best_model.pt\"\n",
    "if os.path.exists(checkpoint_file):\n",
    "    print(f\"Downloading checkpoint: {checkpoint_file}\")\n",
    "    files.download(checkpoint_file)\n",
    "else:\n",
    "    print(\"No checkpoint found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips-header"
   },
   "source": [
    "## 7. Tips & Troubleshooting\n",
    "\n",
    "### GPU Memory Issues\n",
    "If you run out of GPU memory, try:\n",
    "- Reduce `BATCH_SIZE` (try 64 or 32)\n",
    "- Reduce `LATENT_SIZE` (try 32 instead of 48)\n",
    "\n",
    "### Speed Optimization\n",
    "- Use larger batch sizes on GPU (128-256)\n",
    "- Enable mixed precision training (add `--amp` flag)\n",
    "- Use persistent workers for data loading\n",
    "\n",
    "### Monitoring Training\n",
    "- Check `{CHECKPOINT_DIR}/training.log` for detailed logs\n",
    "- Latent images are saved every 10 epochs by default\n",
    "- Best model is saved automatically based on validation loss\n",
    "\n",
    "### Checkpoints in Google Drive\n",
    "All checkpoints are saved to Google Drive, so:\n",
    "- They persist across Colab sessions\n",
    "- You can resume training anytime\n",
    "- You can download them to your local machine\n",
    "\n",
    "### Colab Runtime Limits\n",
    "- Free tier: ~12 hour session limit\n",
    "- Pro tier: ~24 hour session limit\n",
    "- If disconnected, just rerun and resume from checkpoint!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
